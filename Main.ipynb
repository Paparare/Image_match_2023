{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e3d372c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-22T11:51:12.979193Z",
     "iopub.status.busy": "2023-06-22T11:51:12.978391Z",
     "iopub.status.idle": "2023-06-22T11:51:28.510680Z",
     "shell.execute_reply": "2023-06-22T11:51:28.509066Z"
    },
    "papermill": {
     "duration": 15.552396,
     "end_time": "2023-06-22T11:51:28.515834",
     "exception": false,
     "start_time": "2023-06-22T11:51:12.963438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kornia version 0.6.12\n",
      "Pycolmap version 0.4.0\n"
     ]
    }
   ],
   "source": [
    "# General utilities\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from fastprogress import progress_bar\n",
    "import gc\n",
    "import math\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures\n",
    "\n",
    "# CV/ML\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "from PIL import Image\n",
    "import timm\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "\n",
    "# 3D reconstruction\n",
    "import pycolmap\n",
    "\n",
    "import sys\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "\n",
    "import os, argparse, h5py, warnings\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ExifTags\n",
    "\n",
    "print(\"Kornia version\", K.__version__)\n",
    "print(\"Pycolmap version\", pycolmap.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fb12982",
   "metadata": {
    "papermill": {
     "duration": 0.01991,
     "end_time": "2023-06-22T11:51:28.568906",
     "exception": false,
     "start_time": "2023-06-22T11:51:28.548996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ee4b45a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T11:51:28.601217Z",
     "iopub.status.busy": "2023-06-22T11:51:28.600832Z",
     "iopub.status.idle": "2023-06-22T11:51:28.680459Z",
     "shell.execute_reply": "2023-06-22T11:51:28.679213Z"
    },
    "papermill": {
     "duration": 0.09991,
     "end_time": "2023-06-22T11:51:28.682735",
     "exception": false,
     "start_time": "2023-06-22T11:51:28.582825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "NUM_CORES = 2\n",
    "SRC = \"/kaggle/input/image-matching-challenge-2023\"\n",
    "MODEL_DIR = \"/kaggle/input/kornia-local-feature-weights/\"\n",
    "HARDNET_PT = \"/kaggle/input/hardnet8v2/hardnet8v2.pt\"\n",
    "\n",
    "MODEL_DICT = {\n",
    "    \"Keynet\": {\"enable\": True, \"resize_long_edge_to\": 1600},\n",
    "    \"GFTT\":   {\"enable\": True, \"resize_long_edge_to\": 1600},\n",
    "    \"DoG\":    {\"enable\": True, \"resize_long_edge_to\": 1600},\n",
    "    \"Harris\": {\"enable\": True, \"resize_long_edge_to\": 1600},\n",
    "}\n",
    "\n",
    "MATCH_FILTER_RATIO = 0.01\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b1326f8",
   "metadata": {
    "papermill": {
     "duration": 0.013773,
     "end_time": "2023-06-22T11:51:28.710917",
     "exception": false,
     "start_time": "2023-06-22T11:51:28.697144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# datadict setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bc29e83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T11:51:28.740588Z",
     "iopub.status.busy": "2023-06-22T11:51:28.740170Z",
     "iopub.status.idle": "2023-06-22T11:51:28.757322Z",
     "shell.execute_reply": "2023-06-22T11:51:28.756181Z"
    },
    "papermill": {
     "duration": 0.034585,
     "end_time": "2023-06-22T11:51:28.759762",
     "exception": false,
     "start_time": "2023-06-22T11:51:28.725177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2cfa01ab573141e4 / 2fa124afd1f74f38 -> 3 images\n",
      "Reconstruction order: \n",
      " --2cfa01ab573141e4 / 2fa124afd1f74f38\n"
     ]
    }
   ],
   "source": [
    "data_dict = {}\n",
    "\n",
    "with open(f\"{SRC}/sample_submission.csv\", \"r\") as f:\n",
    "    for i, l in enumerate(f):\n",
    "        if l and i > 0:\n",
    "            image, dataset, scene, _, _ = l.strip().split(\",\")\n",
    "            if dataset not in data_dict:\n",
    "                data_dict[dataset] = {}\n",
    "            if scene not in data_dict[dataset]:\n",
    "                data_dict[dataset][scene] = []\n",
    "            data_dict[dataset][scene].append(image)\n",
    "\n",
    "all_scenes = []\n",
    "scene_len = []\n",
    "\n",
    "for dataset in data_dict:\n",
    "    for scene in data_dict[dataset]:\n",
    "        print(f\"{dataset} / {scene} -> {len(data_dict[dataset][scene])} images\")\n",
    "        all_scenes.append((dataset, scene))\n",
    "        scene_len.append(len(data_dict[dataset][scene]))\n",
    "\n",
    "all_scenes = [x for _, x in sorted(zip(scene_len, all_scenes), reverse=True)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d85650c6",
   "metadata": {
    "papermill": {
     "duration": 0.013956,
     "end_time": "2023-06-22T11:51:28.856564",
     "exception": false,
     "start_time": "2023-06-22T11:51:28.842608",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Image loading and Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5c62e2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T11:51:28.886754Z",
     "iopub.status.busy": "2023-06-22T11:51:28.886378Z",
     "iopub.status.idle": "2023-06-22T11:51:28.900224Z",
     "shell.execute_reply": "2023-06-22T11:51:28.899081Z"
    },
    "papermill": {
     "duration": 0.031998,
     "end_time": "2023-06-22T11:51:28.902778",
     "exception": false,
     "start_time": "2023-06-22T11:51:28.870780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_torch_image(fname, device=torch.device(\"cpu\")):\n",
    "    img = K.image_to_tensor(cv2.imread(fname), False).float() / 255.0\n",
    "    img = K.color.bgr_to_rgb(img.to(device))\n",
    "    return img\n",
    "\n",
    "def resize_torch_image(\n",
    "    timg, resize_long_edge_to=None\n",
    "):\n",
    "    h, w = timg.shape[2:]\n",
    "    raw_size = torch.tensor(timg.shape[2:])\n",
    "\n",
    "    scale = float(resize_long_edge_to) / float(max(raw_size[0], raw_size[1]))\n",
    "    scale = min(scale, 1)\n",
    "\n",
    "    h_resized = int(h * scale)\n",
    "    w_resized = int(w * scale)\n",
    "\n",
    "    scale_h = h_resized / h\n",
    "    scale_w = w_resized / w\n",
    "\n",
    "    timg_resized = K.geometry.resize(timg, (h_resized, w_resized), antialias = True)\n",
    "    return timg_resized, scale_h, scale_w"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca4355e7",
   "metadata": {
    "papermill": {
     "duration": 0.013642,
     "end_time": "2023-06-22T11:51:29.008889",
     "exception": false,
     "start_time": "2023-06-22T11:51:28.995247",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Colmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3a282f8",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-06-22T11:51:29.037968Z",
     "iopub.status.busy": "2023-06-22T11:51:29.037610Z",
     "iopub.status.idle": "2023-06-22T11:51:29.071161Z",
     "shell.execute_reply": "2023-06-22T11:51:29.070136Z"
    },
    "papermill": {
     "duration": 0.051246,
     "end_time": "2023-06-22T11:51:29.073943",
     "exception": false,
     "start_time": "2023-06-22T11:51:29.022697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_IMAGE_ID = 2**31 - 1\n",
    "\n",
    "CREATE_CAMERAS_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS cameras (\n",
    "    camera_id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
    "    model INTEGER NOT NULL,\n",
    "    width INTEGER NOT NULL,\n",
    "    height INTEGER NOT NULL,\n",
    "    params BLOB,\n",
    "    prior_focal_length INTEGER NOT NULL)\"\"\"\n",
    "\n",
    "CREATE_IMAGES_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS images (\n",
    "    image_id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
    "    name TEXT NOT NULL UNIQUE,\n",
    "    camera_id INTEGER NOT NULL,\n",
    "    prior_qw REAL,\n",
    "    prior_qx REAL,\n",
    "    prior_qy REAL,\n",
    "    prior_qz REAL,\n",
    "    prior_tx REAL,\n",
    "    prior_ty REAL,\n",
    "    prior_tz REAL,\n",
    "    CONSTRAINT image_id_check CHECK(image_id >= 0 and image_id < {}),\n",
    "    FOREIGN KEY(camera_id) REFERENCES cameras(camera_id))\n",
    "\"\"\".format(\n",
    "    MAX_IMAGE_ID\n",
    ")\n",
    "\n",
    "CREATE_TWO_VIEW_GEOMETRIES_TABLE = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS two_view_geometries (\n",
    "    pair_id INTEGER PRIMARY KEY NOT NULL,\n",
    "    rows INTEGER NOT NULL,\n",
    "    cols INTEGER NOT NULL,\n",
    "    data BLOB,\n",
    "    config INTEGER NOT NULL,\n",
    "    F BLOB,\n",
    "    E BLOB,\n",
    "    H BLOB)\n",
    "\"\"\"\n",
    "\n",
    "CREATE_KEYPOINTS_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS keypoints (\n",
    "    image_id INTEGER PRIMARY KEY NOT NULL,\n",
    "    rows INTEGER NOT NULL,\n",
    "    cols INTEGER NOT NULL,\n",
    "    data BLOB,\n",
    "    FOREIGN KEY(image_id) REFERENCES images(image_id) ON DELETE CASCADE)\n",
    "\"\"\"\n",
    "\n",
    "CREATE_MATCHES_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS matches (\n",
    "    pair_id INTEGER PRIMARY KEY NOT NULL,\n",
    "    rows INTEGER NOT NULL,\n",
    "    cols INTEGER NOT NULL,\n",
    "    data BLOB)\"\"\"\n",
    "\n",
    "CREATE_NAME_INDEX = \"CREATE UNIQUE INDEX IF NOT EXISTS index_name ON images(name)\"\n",
    "\n",
    "CREATE_ALL = \"; \".join(\n",
    "    [\n",
    "        CREATE_CAMERAS_TABLE,\n",
    "        CREATE_IMAGES_TABLE,\n",
    "        CREATE_KEYPOINTS_TABLE,\n",
    "        CREATE_MATCHES_TABLE,\n",
    "        CREATE_TWO_VIEW_GEOMETRIES_TABLE,\n",
    "        CREATE_NAME_INDEX,\n",
    "    ]\n",
    ")\n",
    "\n",
    "def image_ids_to_pair_id(image_id1, image_id2):\n",
    "    if image_id1 > image_id2:\n",
    "        image_id1, image_id2 = image_id2, image_id1\n",
    "    return image_id1 * MAX_IMAGE_ID + image_id2\n",
    "\n",
    "def array_to_blob(array):\n",
    "    return array.tostring()\n",
    "\n",
    "\n",
    "class COLMAPDatabase(sqlite3.Connection):\n",
    "    @staticmethod\n",
    "    def connect(database_path):\n",
    "        return sqlite3.connect(database_path, factory=COLMAPDatabase)\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(COLMAPDatabase, self).__init__(*args, **kwargs)\n",
    "        self.create_tables = lambda: self.executescript(CREATE_ALL)\n",
    "        self.create_cameras_table = lambda: self.executescript(CREATE_CAMERAS_TABLE)\n",
    "        self.create_images_table = lambda: self.executescript(CREATE_IMAGES_TABLE)\n",
    "        self.create_two_view_geometries_table = lambda: self.executescript(CREATE_TWO_VIEW_GEOMETRIES_TABLE)\n",
    "        self.create_keypoints_table = lambda: self.executescript(CREATE_KEYPOINTS_TABLE)\n",
    "        self.create_matches_table = lambda: self.executescript(CREATE_MATCHES_TABLE)\n",
    "        self.create_name_index = lambda: self.executescript(CREATE_NAME_INDEX)\n",
    "\n",
    "    def add_camera(\n",
    "        self, model, width, height, params, prior_focal_length=False, camera_id=None\n",
    "    ):\n",
    "        params = np.asarray(params, np.float64)\n",
    "        cursor = self.execute(\n",
    "            \"INSERT INTO cameras VALUES (?, ?, ?, ?, ?, ?)\",\n",
    "            (\n",
    "                camera_id,\n",
    "                model,\n",
    "                width,\n",
    "                height,\n",
    "                array_to_blob(params),\n",
    "                prior_focal_length,\n",
    "            ),\n",
    "        )\n",
    "        return cursor.lastrowid\n",
    "\n",
    "    def add_image(\n",
    "        self, name, camera_id, prior_q=np.zeros(4), prior_t=np.zeros(3), image_id=None\n",
    "    ):\n",
    "        cursor = self.execute(\n",
    "            \"INSERT INTO images VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\",\n",
    "            (\n",
    "                image_id,\n",
    "                name,\n",
    "                camera_id,\n",
    "                prior_q[0],\n",
    "                prior_q[1],\n",
    "                prior_q[2],\n",
    "                prior_q[3],\n",
    "                prior_t[0],\n",
    "                prior_t[1],\n",
    "                prior_t[2],\n",
    "            ),\n",
    "        )\n",
    "        return cursor.lastrowid\n",
    "\n",
    "    def add_keypoints(self, image_id, keypoints):\n",
    "        assert len(keypoints.shape) == 2\n",
    "        assert keypoints.shape[1] in [2, 4, 6]\n",
    "\n",
    "        keypoints = np.asarray(keypoints, np.float32)\n",
    "        self.execute(\n",
    "            \"INSERT INTO keypoints VALUES (?, ?, ?, ?)\",\n",
    "            (image_id,) + keypoints.shape + (array_to_blob(keypoints),),\n",
    "        )\n",
    "\n",
    "    def add_matches(self, image_id1, image_id2, matches):\n",
    "        assert len(matches.shape) == 2\n",
    "        assert matches.shape[1] == 2\n",
    "\n",
    "        if image_id1 > image_id2:\n",
    "            matches = matches[:, ::-1]\n",
    "\n",
    "        pair_id = image_ids_to_pair_id(image_id1, image_id2)\n",
    "        matches = np.asarray(matches, np.uint32)\n",
    "        self.execute(\n",
    "            \"INSERT INTO matches VALUES (?, ?, ?, ?)\",\n",
    "            (pair_id,) + matches.shape + (array_to_blob(matches),),\n",
    "        )\n",
    "\n",
    "    def add_two_view_geometry(\n",
    "        self,\n",
    "        image_id1,\n",
    "        image_id2,\n",
    "        matches,\n",
    "        F=np.eye(3),\n",
    "        E=np.eye(3),\n",
    "        H=np.eye(3),\n",
    "        config=2,\n",
    "    ):\n",
    "        assert len(matches.shape) == 2\n",
    "        assert matches.shape[1] == 2\n",
    "\n",
    "        if image_id1 > image_id2:\n",
    "            matches = matches[:, ::-1]\n",
    "\n",
    "        pair_id = image_ids_to_pair_id(image_id1, image_id2)\n",
    "        matches = np.asarray(matches, np.uint32)\n",
    "        F = np.asarray(F, dtype=np.float64)\n",
    "        E = np.asarray(E, dtype=np.float64)\n",
    "        H = np.asarray(H, dtype=np.float64)\n",
    "        self.execute(\n",
    "            \"INSERT INTO two_view_geometries VALUES (?, ?, ?, ?, ?, ?, ?, ?)\",\n",
    "            (pair_id,)\n",
    "            + matches.shape\n",
    "            + (\n",
    "                array_to_blob(matches),\n",
    "                config,\n",
    "                array_to_blob(F),\n",
    "                array_to_blob(E),\n",
    "                array_to_blob(H),\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e182a2e8",
   "metadata": {
    "papermill": {
     "duration": 0.013418,
     "end_time": "2023-06-22T11:51:29.101310",
     "exception": false,
     "start_time": "2023-06-22T11:51:29.087892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Image Focal Length, Camera Model, Adding Key Points and Matches. Add to Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be61c394",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T11:51:29.130550Z",
     "iopub.status.busy": "2023-06-22T11:51:29.130161Z",
     "iopub.status.idle": "2023-06-22T11:51:29.151491Z",
     "shell.execute_reply": "2023-06-22T11:51:29.150352Z"
    },
    "papermill": {
     "duration": 0.038884,
     "end_time": "2023-06-22T11:51:29.153835",
     "exception": false,
     "start_time": "2023-06-22T11:51:29.114951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_focal(image_path):\n",
    "    \"\"\"\n",
    "      Obtain the focal length of the image.\n",
    "\n",
    "        :param image_path: The path of the image.\n",
    "        :return: Return the focal length and a boolean value indicating whether the focal length comes from Exif information.\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    max_size = max(image.size)\n",
    "    exif = image.getexif()\n",
    "    exif_ifd = exif.get_ifd(0x8769)\n",
    "    exif.update(exif_ifd)\n",
    "\n",
    "    focal = None\n",
    "    is_from_exif = False\n",
    "    if exif is not None:\n",
    "        focal_35mm = None\n",
    "        for tag, value in exif.items():\n",
    "            focal_35mm = None\n",
    "            if ExifTags.TAGS.get(tag, None) == \"FocalLengthIn35mmFilm\":\n",
    "                focal_35mm = float(value)\n",
    "                is_from_exif = True\n",
    "                break\n",
    "\n",
    "        if focal_35mm is not None:\n",
    "            focal = focal_35mm / 35.0 * max_size\n",
    "\n",
    "    if focal is None:\n",
    "        FOCAL_PRIOR = 1.2\n",
    "        focal = FOCAL_PRIOR * max_size\n",
    "\n",
    "    return focal, is_from_exif\n",
    "\n",
    "\n",
    "def create_camera(db, image_path, camera_model):\n",
    "    \"\"\"\n",
    "    Create a camera model.\n",
    "\n",
    "    :param db: The database object.\n",
    "    :param image_path: The path of the image.\n",
    "    :param camera_model: The camera model type, could be \"simple-pinhole\", \"pinhole\", \"simple-radial\" or \"opencv\".\n",
    "    :return: Return the ID of the created camera model.\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    width, height = image.size\n",
    "\n",
    "    focal, is_from_exif = get_focal(image_path)\n",
    "\n",
    "    if camera_model == \"simple-pinhole\":\n",
    "        model = 0  # simple pinhole\n",
    "        param_arr = np.array([focal, width / 2, height / 2])\n",
    "    if camera_model == \"pinhole\":\n",
    "        model = 1  # pinhole\n",
    "        param_arr = np.array([focal, focal, width / 2, height / 2])\n",
    "    elif camera_model == \"simple-radial\":\n",
    "        model = 2  # simple radial\n",
    "        param_arr = np.array([focal, width / 2, height / 2, 0.1])\n",
    "    elif camera_model == \"opencv\":\n",
    "        model = 4  # opencv\n",
    "        param_arr = np.array([focal, focal, width / 2, height / 2, 0.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "    return db.add_camera(\n",
    "        model, width, height, param_arr, prior_focal_length=is_from_exif\n",
    "    )\n",
    "\n",
    "\n",
    "def add_kpts_matches(db, img_dir, kpts, matches, fms=None):\n",
    "    \"\"\"\n",
    "    Add keypoints and matches.\n",
    "\n",
    "    :param db: The database object.\n",
    "    :param img_dir: The directory of the image.\n",
    "    :param kpts: The dictionary of keypoints, with the filename as the key and keypoints as the value.\n",
    "    :param matches: The dictionary of matches, with the filename as the key and matches as the value.\n",
    "    :param fms: Fundamental matrices, optional parameter.\n",
    "    \"\"\"\n",
    "    fname_to_id = {}\n",
    "\n",
    "    for filename in tqdm(kpts):\n",
    "        path = os.path.join(img_dir, filename)\n",
    "        camera_model = \"simple-radial\"\n",
    "        camera_id = create_camera(db, path, camera_model)\n",
    "        image_id = db.add_image(filename, camera_id)\n",
    "        fname_to_id[filename] = image_id\n",
    "        db.add_keypoints(image_id, kpts[filename])\n",
    "\n",
    "        n_keys = len(matches)\n",
    "        n_total = (n_keys * (n_keys - 1)) // 2\n",
    "\n",
    "    added = set()\n",
    "    with tqdm(total=n_total) as pbar:\n",
    "        for key1 in matches:\n",
    "            for key2 in matches[key1]:\n",
    "                id_1 = fname_to_id[key1]\n",
    "                id_2 = fname_to_id[key2]\n",
    "                pair_id = image_ids_to_pair_id(id_1, id_2)\n",
    "                if pair_id in added:\n",
    "                    warnings.warn(f\"Pair {pair_id} ({id_1}, {id_2}) already added!\")\n",
    "                    continue\n",
    "                db.add_matches(id_1, id_2, matches[key1][key2])\n",
    "                added.add(pair_id)\n",
    "                pbar.update(1)\n",
    "\n",
    "                if fms is not None:\n",
    "                    db.add_two_view_geometry(id_1, id_2, matches[key1][key2], fms[key1][key2], np.eye(3), np.eye(3))\n",
    "\n",
    "    db.commit()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "043fef99",
   "metadata": {
    "papermill": {
     "duration": 0.013779,
     "end_time": "2023-06-22T11:51:29.221302",
     "exception": false,
     "start_time": "2023-06-22T11:51:29.207523",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MyModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02f94c51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T11:51:29.251662Z",
     "iopub.status.busy": "2023-06-22T11:51:29.250731Z",
     "iopub.status.idle": "2023-06-22T11:51:29.267566Z",
     "shell.execute_reply": "2023-06-22T11:51:29.266581Z"
    },
    "papermill": {
     "duration": 0.034898,
     "end_time": "2023-06-22T11:51:29.270031",
     "exception": false,
     "start_time": "2023-06-22T11:51:29.235133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyModel(KF.LocalFeature):\n",
    "    \"\"\"\n",
    "    The model integrates detector + AffNet + HardNet descriptor.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features: int = 5000,\n",
    "        device=torch.device(\"cpu\"),\n",
    "        detector = \"keynet\"\n",
    "    ):\n",
    "        detector_options = [\"keynet\", \"GFTT\", \"Hessian\", \"Harris\", \"DoG\"]\n",
    "        if detector not in detector_options:\n",
    "            raise ValueError(\"Detector must be one of {}\".format(detector_options))\n",
    "\n",
    "        ori_module = (KF.LAFOrienter(angle_detector=KF.OriNet(False)).eval())\n",
    "        ori_module.angle_detector.load_state_dict(torch.load(os.path.join(MODEL_DIR, \"OriNet.pth\"))[\"state_dict\"])\n",
    "\n",
    "        if detector == \"keynet\":\n",
    "            detector = KF.KeyNetDetector(\n",
    "                False,\n",
    "                num_features=num_features,\n",
    "                ori_module=ori_module,\n",
    "                aff_module=KF.LAFAffNetShapeEstimator(False).eval(),\n",
    "            ).to(device)\n",
    "\n",
    "            detector.model.load_state_dict(torch.load(os.path.join(MODEL_DIR, \"keynet_pytorch.pth\"))[\"state_dict\"])\n",
    "        \n",
    "        elif detector == \"GFTT\":\n",
    "            detector = KF.MultiResolutionDetector(\n",
    "                KF.CornerGFTT(),\n",
    "                num_features=num_features,\n",
    "                ori_module=ori_module,\n",
    "                aff_module=KF.LAFAffNetShapeEstimator(False).eval(),\n",
    "            ).to(device)\n",
    "\n",
    "        elif detector == \"Harris\":\n",
    "            detector = KF.MultiResolutionDetector(\n",
    "                KF.CornerHarris(0.04),\n",
    "                num_features=num_features,\n",
    "                ori_module=ori_module,\n",
    "                aff_module=KF.LAFAffNetShapeEstimator(False).eval(),\n",
    "            ).to(device)\n",
    "\n",
    "        elif detector == \"DoG\":\n",
    "            detector = KF.MultiResolutionDetector(\n",
    "                KF.BlobDoGSingle(),\n",
    "                num_features=num_features,\n",
    "                ori_module=ori_module,\n",
    "                aff_module=KF.LAFAffNetShapeEstimator(False).eval(),\n",
    "            ).to(device)\n",
    "\n",
    "        detector.aff.load_state_dict(torch.load(os.path.join(MODEL_DIR, \"AffNet.pth\"))[\"state_dict\"])\n",
    "\n",
    "        hardnet8 = KF.HardNet8(False).eval()\n",
    "        hardnet8.load_state_dict(torch.load(HARDNET_PT))\n",
    "\n",
    "        descriptor = KF.LAFDescriptor(\n",
    "            hardnet8, patch_size=32, grayscale_descriptor=True\n",
    "        ).to(device)\n",
    "        super().__init__(detector, descriptor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c0468c3",
   "metadata": {
    "papermill": {
     "duration": 0.014038,
     "end_time": "2023-06-22T11:51:29.343020",
     "exception": false,
     "start_time": "2023-06-22T11:51:29.328982",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ModelDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8040a198",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T11:51:29.373378Z",
     "iopub.status.busy": "2023-06-22T11:51:29.372955Z",
     "iopub.status.idle": "2023-06-22T11:51:29.387199Z",
     "shell.execute_reply": "2023-06-22T11:51:29.386165Z"
    },
    "papermill": {
     "duration": 0.032126,
     "end_time": "2023-06-22T11:51:29.389712",
     "exception": false,
     "start_time": "2023-06-22T11:51:29.357586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelDetector:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        device=torch.device(\"cuda\"),\n",
    "        resize_long_edge_to=600,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.resize_long_edge_to = resize_long_edge_to\n",
    "        print(\"Longer edge will be resized to\", self.resize_long_edge_to)\n",
    "\n",
    "    def detect_features(self, img_fnames): \n",
    "        \"\"\"\n",
    "        Perform feature detection on the given list of images and return the detection results.\n",
    "\n",
    "        :param img_fnames: List containing image file names\n",
    "        :return: Feature data in the form of a dictionary.\n",
    "        \"\"\"\n",
    "        f_lafs = dict()\n",
    "        f_kpts = dict()\n",
    "        f_descs = dict()\n",
    "        f_raw_size = dict()\n",
    "        print(\"Detecting features\")\n",
    "        for img_path in tqdm(img_fnames):\n",
    "            img_fname = img_path.split(\"/\")[-1]\n",
    "            key = img_fname\n",
    "            with torch.inference_mode():\n",
    "                timg = load_torch_image(img_path, device=device)\n",
    "                raw_size = torch.tensor(timg.shape[2:])\n",
    "                timg_resized, h_scale, w_scale = resize_torch_image(\n",
    "                    timg, self.resize_long_edge_to\n",
    "                )\n",
    "                lafs, _, descs = self.model(K.color.rgb_to_grayscale(timg_resized))  \n",
    "                \n",
    "                # Recover scale\n",
    "                lafs[:, :, 0, :] *= 1 / w_scale\n",
    "                lafs[:, :, 1, :] *= 1 / h_scale\n",
    "                desc_dim = descs.shape[-1]\n",
    "                # Move keypoints to cpu for later colmap operations\n",
    "                kpts = KF.get_laf_center(lafs).reshape(-1, 2).detach().cpu().numpy()\n",
    "                descs = descs.reshape(-1, desc_dim).detach()\n",
    "                f_lafs[key] = lafs.detach()\n",
    "                f_kpts[key] = kpts\n",
    "                f_descs[key] = descs\n",
    "                f_raw_size[key] = raw_size\n",
    "        gc.collect()  \n",
    "        torch.cuda.empty_cache()\n",
    "        return f_lafs, f_kpts, f_descs, f_raw_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afd68d5f",
   "metadata": {
    "papermill": {
     "duration": 0.013225,
     "end_time": "2023-06-22T11:51:29.417202",
     "exception": false,
     "start_time": "2023-06-22T11:51:29.403977",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Laf Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea0e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_idxs(A, dim=0):\n",
    "    \"\"\"\n",
    "    Extracts the unique elements from the PyTorch tensor, and returns the indices of their first occurrence in the original tensor.\n",
    "\n",
    "    Parameters:\n",
    "    A (torch.Tensor): The input PyTorch tensor.\n",
    "    dim (int, optional): The dimension of operation. Default is 0.\n",
    "\n",
    "    Returns:\n",
    "    first_indices (torch.Tensor): The tensor of indices where unique elements first occur in the original tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    unique, idx, counts = torch.unique(\n",
    "        A, dim=dim, sorted=True, return_inverse=True, return_counts=True\n",
    "    )\n",
    "\n",
    "    _, ind_sorted = torch.sort(idx, stable=True)\n",
    "\n",
    "    cum_sum = counts.cumsum(0)\n",
    "\n",
    "    cum_sum = torch.cat((torch.tensor([0], device=cum_sum.device), cum_sum[:-1]))\n",
    "\n",
    "    first_indices = ind_sorted[cum_sum]\n",
    "    \n",
    "    return first_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ffddfed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T11:51:29.447761Z",
     "iopub.status.busy": "2023-06-22T11:51:29.447052Z",
     "iopub.status.idle": "2023-06-22T11:51:29.468826Z",
     "shell.execute_reply": "2023-06-22T11:51:29.467758Z"
    },
    "papermill": {
     "duration": 0.040075,
     "end_time": "2023-06-22T11:51:29.471381",
     "exception": false,
     "start_time": "2023-06-22T11:51:29.431306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LafMatcher:\n",
    "    def __init__(self, min_matches=15, device=\"cuda\"):\n",
    "'''\n",
    "        Initialize LafMatcher class\n",
    "\n",
    "        min_matches: Minimum number of matches\n",
    "        device: Computing device, default is \"cuda\"\n",
    "        matcher: Matching method, default is \"adalam\"\n",
    "        Initialize adalam configuration\n",
    "'''\n",
    "        self.adalam_config = KF.adalam.get_adalam_default_config()\n",
    "        self.adalam_config[\"force_seed_mnn\"] = True\n",
    "        self.adalam_config[\"search_expansion\"] = 16\n",
    "        self.adalam_config[\"ransac_iters\"] = 256\n",
    "        self.adalam_config[\"device\"] = device\n",
    "        self.min_matches = min_matches\n",
    "        self.matcher = \"adalam\"\n",
    "\n",
    "    def match(self, img_fnames, f_lafs, f_kpts, f_descs, f_raw_size):\n",
    "        \"\"\"\n",
    "        Execute the matching operation.\n",
    "        img_fnames: List of image filenames.\n",
    "        f_lafs: Intrinsic affine features of the image.\n",
    "        f_kpts: Keypoints of the image.\n",
    "        f_descs: Descriptors of the image.\n",
    "        f_raw_size: Original size of the image.\n",
    "        get_roi: Whether to compute the Region of Interest (ROI), default is False.\n",
    "        \"\"\"\n",
    "\n",
    "        num_imgs = len(img_fnames)\n",
    "        print(\"Matching to get index pairs\")\n",
    "        pair_count = 0\n",
    "        f_matches = defaultdict(dict)\n",
    "        f_rois = defaultdict(dict)\n",
    "\n",
    "        for idx1 in tqdm(range(num_imgs - 1)):\n",
    "            for idx2 in range(idx1 + 1, num_imgs):\n",
    "                fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
    "                key1, key2 = fname1.split(\"/\")[-1], fname2.split(\"/\")[-1]\n",
    "                lafs1 = f_lafs[key1]\n",
    "                lafs2 = f_lafs[key2]\n",
    "                desc1 = f_descs[key1]\n",
    "                desc2 = f_descs[key2]\n",
    "                \n",
    "                hw1, hw2 = f_raw_size[key1], f_raw_size[key2]\n",
    "\n",
    "                # Match using adalam\n",
    "                # dists: Each element in the tensor is a distance, representing the distance between the i-th feature point of the first image and the j-th feature point of the second image.\n",
    "                # idxs: Each element in the tensor is an index pair (i, j), indicating that the i-th feature point of the first image is matched with the j-th feature point of the second image.\n",
    "                dists, idxs = KF.match_adalam(\n",
    "                    desc1,\n",
    "                    desc2,\n",
    "                    lafs1,\n",
    "                    lafs2,  \n",
    "                    hw1=hw1,\n",
    "                    hw2=hw2,\n",
    "                    config=self.adalam_config,\n",
    "                )\n",
    "\n",
    "                if dists.mean().cpu().numpy() < 0.5:\n",
    "                    first_indices = get_unique_idxs(idxs[:, 1])\n",
    "                    idxs = idxs[first_indices]\n",
    "                    dists = dists[first_indices]\n",
    "                    n_matches = len(idxs)\n",
    "\n",
    "                    if n_matches >= self.min_matches:\n",
    "                        pair_count += 1\n",
    "                        f_matches[key1][key2] = (\n",
    "                            idxs.detach().cpu().numpy().reshape(-1, 2)\n",
    "                        )\n",
    "\n",
    "        print(f\" Get {pair_count} from {int(num_imgs * (num_imgs-1)/2)} possible pairs\")\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        return f_kpts, f_matches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d22cac8",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86045301",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T11:51:29.681785Z",
     "iopub.status.busy": "2023-06-22T11:51:29.681067Z",
     "iopub.status.idle": "2023-06-22T11:51:40.661454Z",
     "shell.execute_reply": "2023-06-22T11:51:40.660352Z"
    },
    "papermill": {
     "duration": 10.998212,
     "end_time": "2023-06-22T11:51:40.664215",
     "exception": false,
     "start_time": "2023-06-22T11:51:29.666003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/1809304848.py:43: DeprecationWarning: `LAFAffNetShapeEstimator` default behaviour is changed and now it does preserve original LAF orientation. Make sure your code accounts for this.\n",
      "  aff_module=KF.LAFAffNetShapeEstimator(False).eval(),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init AffNetHardNetDetector\n",
      "Longer edge will be resized to 1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/1809304848.py:55: DeprecationWarning: `LAFAffNetShapeEstimator` default behaviour is changed and now it does preserve original LAF orientation. Make sure your code accounts for this.\n",
      "  aff_module=KF.LAFAffNetShapeEstimator(False).eval(),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init AffNetHardNetDetector\n",
      "Longer edge will be resized to 1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/1809304848.py:71: DeprecationWarning: `LAFAffNetShapeEstimator` default behaviour is changed and now it does preserve original LAF orientation. Make sure your code accounts for this.\n",
      "  aff_module=KF.LAFAffNetShapeEstimator(False).eval(),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init AffNetHardNetDetector\n",
      "Longer edge will be resized to 1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/1809304848.py:63: DeprecationWarning: `LAFAffNetShapeEstimator` default behaviour is changed and now it does preserve original LAF orientation. Make sure your code accounts for this.\n",
      "  aff_module=KF.LAFAffNetShapeEstimator(False).eval(),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init AffNetHardNetDetector\n",
      "Longer edge will be resized to 1600\n"
     ]
    }
   ],
   "source": [
    "if MODEL_DICT[\"Keynet\"][\"enable\"]:\n",
    "    keynet_model = (\n",
    "        MyModel(num_features=8000, device=device, detector=\"keynet\")\n",
    "        .to(device)\n",
    "        .eval()\n",
    "    )\n",
    "    keynet_detector = ModelDetector(keynet_model, resize_long_edge_to=MODEL_DICT[\"Keynet\"][\"resize_long_edge_to\"])\n",
    "\n",
    "if MODEL_DICT[\"GFTT\"][\"enable\"]:\n",
    "    gftt_model = (\n",
    "        MyModel(num_features=8000, device=device, detector=\"GFTT\")\n",
    "        .to(device)\n",
    "        .eval()\n",
    "    )\n",
    "    gftt_detector = ModelDetector(gftt_model, resize_long_edge_to=MODEL_DICT[\"GFTT\"][\"resize_long_edge_to\"])\n",
    "\n",
    "if MODEL_DICT[\"DoG\"][\"enable\"]:\n",
    "    DoG_model = (\n",
    "        MyModel(num_features=8000, device=device, detector=\"DoG\")\n",
    "        .to(device)\n",
    "        .eval()\n",
    "    )\n",
    "    DoG_detector = ModelDetector(DoG_model, resize_long_edge_to=MODEL_DICT[\"DoG\"][\"resize_long_edge_to\"])\n",
    "\n",
    "if MODEL_DICT[\"Harris\"][\"enable\"]:\n",
    "    harris_model = (\n",
    "        MyModel(num_features=8000, device=device, detector=\"Harris\")\n",
    "        .to(device)\n",
    "        .eval()\n",
    "    )\n",
    "    harris_detector = ModelDetector(harris_model, resize_long_edge_to=MODEL_DICT[\"Harris\"][\"resize_long_edge_to\"])\n",
    "\n",
    "laf_matcher = LafMatcher(device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "709e431b",
   "metadata": {
    "papermill": {
     "duration": 0.013414,
     "end_time": "2023-06-22T11:51:29.498700",
     "exception": false,
     "start_time": "2023-06-22T11:51:29.485286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Merge keypoints and matches， Compute fundamental matrix， Filter matching points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1b20d3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T11:51:29.528718Z",
     "iopub.status.busy": "2023-06-22T11:51:29.528372Z",
     "iopub.status.idle": "2023-06-22T11:51:29.549099Z",
     "shell.execute_reply": "2023-06-22T11:51:29.548062Z"
    },
    "papermill": {
     "duration": 0.038726,
     "end_time": "2023-06-22T11:51:29.551463",
     "exception": false,
     "start_time": "2023-06-22T11:51:29.512737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_kpts_matches(kpts, matches, new_kpts, new_matches):\n",
    "    \"\"\"\n",
    "    Merge keypoints (kpts) and matches.\n",
    "\n",
    "    Parameters:\n",
    "    kpts: dict, original keypoints.\n",
    "    matches: dict, original matching points.\n",
    "    new_kpts: dict, new keypoints.\n",
    "    new_matches: dict, new matching points.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing merged keypoints and matching points.\n",
    "    \"\"\"\n",
    "    prev_len = dict()\n",
    "\n",
    "    for new_key in new_kpts:\n",
    "        if new_key in kpts:\n",
    "            old_len = len(kpts[new_key])\n",
    "            kpts[new_key] = np.concatenate([kpts[new_key], new_kpts[new_key]], axis=0)\n",
    "        else:\n",
    "            old_len = 0\n",
    "            kpts[new_key] = new_kpts[new_key]\n",
    "        prev_len[new_key] = old_len\n",
    "\n",
    "    for new_key1 in new_matches:\n",
    "        for new_key2 in new_matches[new_key1]:\n",
    "            old_len1 = prev_len[new_key1]\n",
    "            old_len2 = prev_len[new_key2]\n",
    "            new_match = new_matches[new_key1][new_key2] + [old_len1, old_len2]\n",
    "\n",
    "            if new_key1 in matches and new_key2 in matches[new_key1]:\n",
    "                matches[new_key1][new_key2] = np.concatenate(\n",
    "                    [\n",
    "                        matches[new_key1][new_key2],\n",
    "                        new_match,\n",
    "                    ],\n",
    "                    axis=0,\n",
    "                )\n",
    "            else:\n",
    "                if new_key1 not in matches:\n",
    "                    matches[new_key1] = dict()\n",
    "                matches[new_key1][new_key2] = new_match\n",
    "    return kpts, matches\n",
    "\n",
    "\n",
    "def get_fms(kpts, matches):\n",
    "    \"\"\"\n",
    "    Compute the fundamental matrix (Fundamental Matrix) based on the input keypoints and matching points.\n",
    "    The fundamental matrix is a 3x3 matrix that represents the geometric relationship between two cameras (or two viewpoints) (the two cameras capture two different viewpoints of the same scene).\n",
    "    \"\"\"\n",
    "\n",
    "    fms = defaultdict(dict)\n",
    "    \n",
    "    print(\"Get Fundamental Matrix\")\n",
    "\n",
    "    for key1 in tqdm(matches):\n",
    "        for key2 in matches[key1]:\n",
    "\n",
    "            match = matches[key1][key2]\n",
    "\n",
    "            mkpts1 = kpts[key1][match[:, 0]]\n",
    "            mkpts2 = kpts[key2][match[:, 1]]\n",
    "\n",
    "            Fm, inliers = cv2.findFundamentalMat(mkpts1, mkpts2, cv2.USAC_MAGSAC, 5, 0.9999, 50000)\n",
    "            new_match = match[inliers.ravel() == 1]\n",
    "            matches[key1][key2] = new_match\n",
    "            fms[key1][key2] = Fm\n",
    "\n",
    "    return kpts, matches, fms\n",
    "\n",
    "\n",
    "\n",
    "def select_matches(matches, keep_ratio = 0.01):\n",
    "    \"\"\"\n",
    "    Select matching points.\n",
    "\n",
    "    Parameters:\n",
    "    matches: dict, original matching points.\n",
    "    keep_ratio: float, proportion of matching points to retain, default is 0.01.\n",
    "\n",
    "    Returns:\n",
    "    dict: Retained matching points.\n",
    "    \"\"\"\n",
    "    max_matches = defaultdict(int)\n",
    "    old_matches_count = 0\n",
    "    for key1 in matches:\n",
    "        for key2 in matches[key1]:\n",
    "            max_matches[key1] = max(max_matches[key1], len(matches[key1][key2]))\n",
    "            max_matches[key2] = max(max_matches[key2], len(matches[key1][key2]))\n",
    "            old_matches_count +=1\n",
    "\n",
    "    new_matches_count = 0\n",
    "    new_matches = defaultdict(dict)\n",
    "    for key1 in matches:\n",
    "        for key2 in matches[key1]:\n",
    "            n_matches = len(matches[key1][key2])\n",
    "            if n_matches > max_matches[key1] * keep_ratio or n_matches > max_matches[key2] * keep_ratio:\n",
    "                new_matches[key1][key2] = matches[key1][key2]\n",
    "                new_matches_count+=1\n",
    "\n",
    "    return new_matches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "404dc005",
   "metadata": {
    "papermill": {
     "duration": 0.014183,
     "end_time": "2023-06-22T11:51:40.739204",
     "exception": false,
     "start_time": "2023-06-22T11:51:40.725021",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature detection and matching, results written to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c82b5b79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T11:51:40.770444Z",
     "iopub.status.busy": "2023-06-22T11:51:40.769435Z",
     "iopub.status.idle": "2023-06-22T11:51:40.789099Z",
     "shell.execute_reply": "2023-06-22T11:51:40.788072Z"
    },
    "papermill": {
     "duration": 0.038176,
     "end_time": "2023-06-22T11:51:40.791664",
     "exception": false,
     "start_time": "2023-06-22T11:51:40.753488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_scene_db(dataset, scene):\n",
    "    \"\"\"\n",
    "    Perform feature detection and matching on a 3D scene, then write the results to the database.\n",
    "\n",
    "    Parameters:\n",
    "    dataset -- Name of the dataset\n",
    "    scene -- Name of the scene\n",
    "\n",
    "    Returns:\n",
    "    matching_time -- Time taken for feature detection and matching.\n",
    "    \"\"\"\n",
    "\n",
    "    feature_det_start = time()\n",
    "\n",
    "    img_dir = f\"{SRC}/test/{dataset}/{scene}/images\"\n",
    "    if not os.path.exists(img_dir):\n",
    "        print(\"Image dir does not exist:\", img_dir)\n",
    "        return\n",
    "\n",
    "    img_fnames = [f\"{SRC}/test/{x}\" for x in data_dict[dataset][scene]]\n",
    "    print(f\"Got {len(img_fnames)} images\")\n",
    "\n",
    "    matches = dict()\n",
    "    kpts = dict()\n",
    "\n",
    "    if MODEL_DICT[\"Keynet\"][\"enable\"]:\n",
    "        f_lafs, f_kpts, f_descs, f_raw_size = keynet_detector.detect_features(img_fnames)\n",
    "        keynet_kpts, keynet_matches = laf_matcher.match(\n",
    "            img_fnames, f_lafs, f_kpts, f_descs, f_raw_size\n",
    "        )\n",
    "        kpts, matches = merge_kpts_matches(kpts, matches, keynet_kpts, keynet_matches)\n",
    "\n",
    "    if MODEL_DICT[\"GFTT\"][\"enable\"]:\n",
    "        gftt_lafs, gftt_kpts, gftt_descs, gftt_raw_size = gftt_detector.detect_features(img_fnames)\n",
    "        gftt_kpts, gftt_matches = laf_matcher.match(\n",
    "            img_fnames, gftt_lafs, gftt_kpts, gftt_descs, gftt_raw_size\n",
    "        )\n",
    "        kpts, matches = merge_kpts_matches(kpts, matches, gftt_kpts, gftt_matches)\n",
    "\n",
    "    if MODEL_DICT[\"DoG\"][\"enable\"]:\n",
    "        DoG_lafs, DoG_kpts, DoG_descs, DoG_raw_size = DoG_detector.detect_features(img_fnames)\n",
    "        DoG_kpts, DoG_matches = laf_matcher.match(\n",
    "            img_fnames, DoG_lafs, DoG_kpts, DoG_descs, DoG_raw_size\n",
    "        )\n",
    "        kpts, matches = merge_kpts_matches(kpts, matches, DoG_kpts, DoG_matches)\n",
    "\n",
    "    if MODEL_DICT[\"Harris\"][\"enable\"]:\n",
    "        harris_lafs, harris_kpts, harris_descs, harris_raw_size = harris_detector.detect_features(img_fnames)\n",
    "        harris_kpts, harris_matches = laf_matcher.match(\n",
    "            img_fnames, harris_lafs, harris_kpts, harris_descs, harris_raw_size\n",
    "        )\n",
    "        kpts, matches = merge_kpts_matches(kpts, matches, harris_kpts, harris_matches)\n",
    "\n",
    "    kpts, matches, fms = get_fms(kpts, matches)\n",
    "\n",
    "    matches = select_matches(matches, MATCH_FILTER_RATIO)\n",
    "\n",
    "    feature_dir = f\"featureout/{dataset}_{scene}\"\n",
    "    os.makedirs(feature_dir, exist_ok=True)\n",
    "    database_path = f\"{feature_dir}/colmap.db\"\n",
    "    if os.path.isfile(database_path):\n",
    "        os.remove(database_path)\n",
    "\n",
    "    db = COLMAPDatabase.connect(database_path)\n",
    "    db.create_tables()\n",
    "    print(\"Add kpts and matches to database\")\n",
    "    add_kpts_matches(db, img_dir, kpts, matches, fms)\n",
    "    feature_det_end = time()\n",
    "    matching_time = feature_det_end - feature_det_start\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return matching_time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4821204f",
   "metadata": {
    "papermill": {
     "duration": 0.013847,
     "end_time": "2023-06-22T11:51:40.820367",
     "exception": false,
     "start_time": "2023-06-22T11:51:40.806520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Reconstruct 3D model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15d460bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T11:51:40.850333Z",
     "iopub.status.busy": "2023-06-22T11:51:40.849947Z",
     "iopub.status.idle": "2023-06-22T11:51:40.863427Z",
     "shell.execute_reply": "2023-06-22T11:51:40.862276Z"
    },
    "papermill": {
     "duration": 0.031221,
     "end_time": "2023-06-22T11:51:40.865818",
     "exception": false,
     "start_time": "2023-06-22T11:51:40.834597",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reconstruct_from_db(dataset, scene):\n",
    "    \"\"\"\n",
    "    Reconstruct a 3D model from the database.\n",
    "\n",
    "    Parameters:\n",
    "    dataset (str): Name of the dataset.\n",
    "    scene (str): Name of the scene.\n",
    "\n",
    "    Returns:\n",
    "    tuple: The reconstruction results and the time taken for reconstruction.\n",
    "    \"\"\"\n",
    "\n",
    "    scene_result = {}\n",
    "    reconst_start = time()\n",
    "\n",
    "    img_dir = f\"{SRC}/test/{dataset}/{scene}/images\"\n",
    "    if not os.path.exists(img_dir):\n",
    "        print(\"Image dir does not exist:\", img_dir)\n",
    "        return\n",
    "\n",
    "    database_path = f\"featureout/{dataset}_{scene}/colmap.db\"\n",
    "    db = COLMAPDatabase.connect(database_path)\n",
    "    output_path = f\"featureout/{dataset}_{scene}/colmap_rec\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    gc.collect()\n",
    "    t = time()\n",
    "\n",
    "    mapper_options = pycolmap.IncrementalMapperOptions()\n",
    "    mapper_options.min_model_size = 3\n",
    "\n",
    "    maps = pycolmap.incremental_mapping(\n",
    "        database_path=database_path,\n",
    "        image_path=img_dir,\n",
    "        output_path=output_path,\n",
    "        options=mapper_options,\n",
    "    )\n",
    "    print(maps)\n",
    "    t = time() - t\n",
    "    print(f\"Reconstruction done in  {t:.4f} sec\")\n",
    "\n",
    "\n",
    "    imgs_registered = 0\n",
    "    best_idx = None\n",
    "    print(\"Looking for the best reconstruction\")\n",
    "    if isinstance(maps, dict):\n",
    "        for idx1, rec in maps.items():\n",
    "            if len(rec.images) > imgs_registered:\n",
    "                imgs_registered = len(rec.images)\n",
    "                best_idx = idx1\n",
    "\n",
    "    if best_idx is not None:\n",
    "        for k, im in maps[best_idx].images.items():\n",
    "            key1 = f\"{dataset}/{scene}/images/{im.name}\"\n",
    "            scene_result[key1] = {}\n",
    "            scene_result[key1][\"R\"] = deepcopy(im.rotmat())\n",
    "            scene_result[key1][\"t\"] = deepcopy(np.array(im.tvec))\n",
    "\n",
    "    gc.collect()\n",
    "    reconst_end = time()\n",
    "    reconst_time = reconst_end - reconst_start\n",
    "    return scene_result, reconst_time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ce3ed1d",
   "metadata": {
    "papermill": {
     "duration": 0.014498,
     "end_time": "2023-06-22T11:51:40.894726",
     "exception": false,
     "start_time": "2023-06-22T11:51:40.880228",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "033d2822",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-06-22T11:51:40.925071Z",
     "iopub.status.busy": "2023-06-22T11:51:40.924704Z",
     "iopub.status.idle": "2023-06-22T11:51:41.068574Z",
     "shell.execute_reply": "2023-06-22T11:51:41.067046Z"
    },
    "papermill": {
     "duration": 0.162365,
     "end_time": "2023-06-22T11:51:41.071394",
     "exception": false,
     "start_time": "2023-06-22T11:51:40.909029",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2cfa01ab573141e4 2fa124afd1f74f38\n",
      "Image dir does not exist: /kaggle/input/image-matching-challenge-2023/test/2cfa01ab573141e4/2fa124afd1f74f38/images\n",
      "Image dir does not exist: /kaggle/input/image-matching-challenge-2023/test/2cfa01ab573141e4/2fa124afd1f74f38/images\n"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "time_dict = dict()\n",
    "\n",
    "for dataset in data_dict:\n",
    "    datasets.append(dataset)\n",
    "out_results = defaultdict(dict)\n",
    "total_start = time()\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=NUM_CORES) as executors:\n",
    "    futures = defaultdict(dict)\n",
    "\n",
    "    for dataset, scene in all_scenes:\n",
    "        print(dataset, scene)\n",
    "        time_dict[\"matching-\" + scene] = generate_scene_db(dataset, scene)\n",
    "        futures[dataset][scene] = executors.submit(reconstruct_from_db, dataset, scene)\n",
    "\n",
    "    for dataset, scene in all_scenes:\n",
    "        result = futures[dataset][scene].result()\n",
    "        if result is not None:\n",
    "            out_results[dataset][scene], time_dict[\"reconst-\" + scene] = result\n",
    "total_end = time()\n",
    "time_dict[\"TOTAL\"] = total_end - total_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41c5723b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T11:51:41.172309Z",
     "iopub.status.busy": "2023-06-22T11:51:41.171968Z",
     "iopub.status.idle": "2023-06-22T11:51:41.177716Z",
     "shell.execute_reply": "2023-06-22T11:51:41.176727Z"
    },
    "papermill": {
     "duration": 0.023101,
     "end_time": "2023-06-22T11:51:41.179911",
     "exception": false,
     "start_time": "2023-06-22T11:51:41.156810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def arr_to_str(a):\n",
    "    return \";\".join([str(x) for x in a.reshape(-1)])\n",
    "\n",
    "def create_submission(out_results, data_dict):\n",
    "    with open(\"submission.csv\", \"w\") as f:\n",
    "        # 写入列名\n",
    "        f.write(\"image_path,dataset,scene,rotation_matrix,translation_vector\\n\")\n",
    "        for dataset in data_dict:\n",
    "            if dataset in out_results:\n",
    "                res = out_results[dataset]\n",
    "            else:\n",
    "                res = {}\n",
    "            for scene in data_dict[dataset]:\n",
    "                if scene in res:\n",
    "                    scene_res = res[scene]\n",
    "                else:\n",
    "                    scene_res = {\"R\": {}, \"t\": {}}\n",
    "                for image in data_dict[dataset][scene]:\n",
    "                    if image in scene_res:\n",
    "                        print(image)\n",
    "                        R = scene_res[image][\"R\"].reshape(-1)\n",
    "                        T = scene_res[image][\"t\"].reshape(-1)\n",
    "                    else:\n",
    "                        R = np.eye(3).reshape(-1)\n",
    "                        T = np.zeros((3))\n",
    "                    f.write(\n",
    "                        f\"{image},{dataset},{scene},{arr_to_str(R)},{arr_to_str(T)}\\n\"\n",
    "                    )\n",
    "\n",
    "create_submission(out_results, data_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 44.217135,
   "end_time": "2023-06-22T11:51:44.377634",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-22T11:51:00.160499",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
